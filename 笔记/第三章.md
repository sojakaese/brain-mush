# 第三章 索引构建

## 1.1 Embedding
1. 复习Embedding的概念
2. Embedding在RAG中的应用流程：离线索引构建, 在线查询检索, 相似度计算, Top-K 召回上下文

## 1.2 Embedding 技术发展
1.静态词嵌入 Word2Vec GloVe
2.动态词嵌入 BERT, GPT, RoBERTa, XLNet, XLM, DistilBERT, ALBERT, BART, T5, GPT-3
3.RAG 框架的提出，旨在解决大型语言模型知识固化: 领域自适应能力, 多粒度与多模态支持, 检索效率与混合检索

## 1.3 嵌入模型训练原理
本质：嵌入模型的核心通常是Transformer的Encoder，其两大训练任务
- 掩码语言模型 (Masked Language Model, MLM)
- 下一句预测 (Next Sentence Prediction, NSP)

现代嵌入模型会引入针对性更强的训练策略：
- 度量学习 (Metric Learning) ：直接以“相似度”作为优化目标。
  - 方法：收集大量相关的文本对
  - 目标：是优化向量空间中的相对距离,优化排序关系,而非追求绝对的相似度值（如 1 或 0），因为过度追求极端值可能导致模型过拟合。
- 对比学习 (Contrastive Learning) ：在向量空间中，将相似的样本“拉近”，将不相似的样本“推远”。
  - 方法：构建一个三元组（Anchor, Positive, Negative）。其中，Anchor 和 Positive 是相关的（例如，同一个问题的两种不同问法），Anchor 和 Negative 是不相关的。
  - 目标：训练的目标是让 distance(Anchor, Positive) 尽可能小，同时让 distance(Anchor, Negative) 尽可能大。

## 1.4 嵌入模型选型指南
参考 [MTEB (Massive Text Embedding Benchmark) ](https://huggingface.co/spaces/mteb/leaderboard)

迭代测试与优化: 
1.**确定基线 (Baseline)**：根据上述维度，选择几个符合要求的模型作为你的初始基准模型。
2.**私有评测集**：根据真实业务数据，手动创建一批高质量的评测样本，每个样本包含一个典型用户问题和它对应的标准答案（或最相关的文档块）。
3. 迭代优化：
使用基线模型在你的私有评测集上运行，评估其召回的准确率和相关性。
如果效果不理想，可以尝试更换模型，或者调整 RAG 流程的其他环节（如文本分块策略）。
通过几轮的对比测试和迭代优化，最终选出在你的特定场景下表现最佳的那个“心仪”模型。

## 2.1 多模态嵌入
需求：多模态的数据映射到同一个共享的向量空间，解决**跨模态对齐** (Cross-modal Alignment) 

## 2.2 CLIP 模型
OpenAI 的 CLIP (Contrastive Language-Image Pre-training) : 将传统的分类任务，转化为一个“图文检索”问题
- 采用**双编码器架构 (Dual-Encoder Architecture)**，包含一个图像编码器和一个文本编码器，分别将图像和文本映射到同一个共享的向量空间中。
- 在训练时采用了对比学习 (Contrastive Learning) 策略。在处理一批图文数据时，模型的目标是：最大化正确图文对的向量相似度，同时最小化所有错误配对的相似度。通过这种“拉近正例，推远负例”的方式，模型从海量数据中学会了将语义相关的图像和文本在向量空间中拉近。

练习里，如果把纯文字改成 blue whale 或者 blue shark 会有不同程度的匹配度下降，改成 red monkey 会进一步下降。

# 3.1 向量数据库
- 向量数据库特点：高效的相似性搜索, 高维数据存储与管理, 查询能力, 可扩展与高可用. 
- 向量数据库和传统数据库有着互补关系：利用传统数据库存储业务元数据和结构化信息，而向量数据库则专门负责处理和检索由 AI 模型产生的海量向量数据。

# 3.2 工作原理
**向量数据库四层架构**：
- 存储层：存储向量数据和元数据，优化存储效率，支持分布式存储
- 索引层：维护索引算法（HNSW、LSH、PQ等），创建和优化索引，支持索引调整
- 查询层：处理查询请求，支持混合查询，实现查询优化
- 服务层：管理客户端连接，提供监控和日志，实现安全管理

**技术手段**：
- 基于树的方法：如 Annoy 使用的随机投影树，通过树形结构实现对数复杂度的搜索
- 基于哈希的方法：如 LSH（局部敏感哈希），通过哈希函数将相似向量映射到同一“桶”
- 基于图的方法：如 HNSW（分层可导航小世界图），通过多层邻近图结构实现快速搜索
- 基于量化的方法：如 Faiss 的 IVF 和 PQ，通过聚类和量化压缩向量

# 3.4 本地向量存储：FAISS 案例
FAISS 本质上是一个算法库，它将索引直接保存为本地文件。有faiss-cpu faiss-gpu两种库。

