# 第三章 索引构建

## 1.1 Embedding
1. 复习Embedding的概念
2. Embedding在RAG中的应用流程：离线索引构建, 在线查询检索, 相似度计算, Top-K 召回上下文

## 1.2 Embedding 技术发展
1.静态词嵌入 Word2Vec GloVe
2.动态词嵌入 BERT, GPT, RoBERTa, XLNet, XLM, DistilBERT, ALBERT, BART, T5, GPT-3
3.RAG 框架的提出，旨在解决大型语言模型知识固化: 领域自适应能力, 多粒度与多模态支持, 检索效率与混合检索

## 1.3 嵌入模型训练原理
本质：嵌入模型的核心通常是Transformer的Encoder，其两大训练任务
- 掩码语言模型 (Masked Language Model, MLM)
- 下一句预测 (Next Sentence Prediction, NSP)

现代嵌入模型会引入针对性更强的训练策略：
- 度量学习 (Metric Learning) ：直接以“相似度”作为优化目标。
  - 方法：收集大量相关的文本对
  - 目标：是优化向量空间中的相对距离,优化排序关系,而非追求绝对的相似度值（如 1 或 0），因为过度追求极端值可能导致模型过拟合。
- 对比学习 (Contrastive Learning) ：在向量空间中，将相似的样本“拉近”，将不相似的样本“推远”。
  - 方法：构建一个三元组（Anchor, Positive, Negative）。其中，Anchor 和 Positive 是相关的（例如，同一个问题的两种不同问法），Anchor 和 Negative 是不相关的。
  - 目标：训练的目标是让 distance(Anchor, Positive) 尽可能小，同时让 distance(Anchor, Negative) 尽可能大。

## 1.4 嵌入模型选型指南
参考 [MTEB (Massive Text Embedding Benchmark) ](https://huggingface.co/spaces/mteb/leaderboard)

迭代测试与优化: 
1.**确定基线 (Baseline)**：根据上述维度，选择几个符合要求的模型作为你的初始基准模型。
2.**私有评测集**：根据真实业务数据，手动创建一批高质量的评测样本，每个样本包含一个典型用户问题和它对应的标准答案（或最相关的文档块）。
3. 迭代优化：
使用基线模型在你的私有评测集上运行，评估其召回的准确率和相关性。
如果效果不理想，可以尝试更换模型，或者调整 RAG 流程的其他环节（如文本分块策略）。
通过几轮的对比测试和迭代优化，最终选出在你的特定场景下表现最佳的那个“心仪”模型。

## 2.1 多模态嵌入
需求：多模态的数据映射到同一个共享的向量空间，解决**跨模态对齐** (Cross-modal Alignment) 

## 2.2 CLIP 模型
OpenAI 的 CLIP (Contrastive Language-Image Pre-training) : 将传统的分类任务，转化为一个“图文检索”问题
- 采用**双编码器架构 (Dual-Encoder Architecture)**，包含一个图像编码器和一个文本编码器，分别将图像和文本映射到同一个共享的向量空间中。
- 在训练时采用了对比学习 (Contrastive Learning) 策略。在处理一批图文数据时，模型的目标是：最大化正确图文对的向量相似度，同时最小化所有错误配对的相似度。通过这种“拉近正例，推远负例”的方式，模型从海量数据中学会了将语义相关的图像和文本在向量空间中拉近。

练习：如果把纯文字改成 blue whale 或者 blue shark 会有不同程度的匹配度下降，改成 red monkey 会进一步下降。

# 3.1 向量数据库
- 向量数据库特点：高效的相似性搜索, 高维数据存储与管理, 查询能力, 可扩展与高可用. 
- 向量数据库和传统数据库有着互补关系：利用传统数据库存储业务元数据和结构化信息，而向量数据库则专门负责处理和检索由 AI 模型产生的海量向量数据。

# 3.2 工作原理
**向量数据库四层架构**：
- 存储层：存储向量数据和元数据，优化存储效率，支持分布式存储
- 索引层：维护索引算法（HNSW、LSH、PQ等），创建和优化索引，支持索引调整
- 查询层：处理查询请求，支持混合查询，实现查询优化
- 服务层：管理客户端连接，提供监控和日志，实现安全管理

**技术手段**：
- 基于树的方法：如 Annoy 使用的随机投影树，通过树形结构实现对数复杂度的搜索
- 基于哈希的方法：如 LSH（局部敏感哈希），通过哈希函数将相似向量映射到同一“桶”
- 基于图的方法：如 HNSW（分层可导航小世界图），通过多层邻近图结构实现快速搜索
- 基于量化的方法：如 Faiss 的 IVF 和 PQ，通过聚类和量化压缩向量

# 3.4 本地向量存储：FAISS 案例
FAISS 本质上是一个算法库，它将索引直接保存为本地文件。有faiss-cpu faiss-gpu两种库。

练习：llamaIndex会给文本嵌入创造一个向量数据仓库，可以存在本地和云端，包含文本 向量 和索引三条文件，也可以从文件创建向量仓库，并进行各种惭怍。


# 4 Milvus实践



# 5 LlamaIndex 的索引优化方案 
**句子窗口检索（Sentence Window Retrieval）**:
- 索引阶段：在构建索引时，文档被分割成单个句子。每个句子都作为一个独立的“节点（Node）”存入向量数据库。同时，每个句子节点都会在元数据（metadata）中存储其上下文窗口，即该句子原文中的前N个和后N个句子。这个窗口内的文本不会被索引，仅仅是作为元数据存储。
- 检索阶段：当用户发起查询时，系统会在所有单一句子节点上执行相似度搜索。因为句子是表达完整语义的最小单位，所以这种方式可以非常精确地定位到与用户问题最相关的核心信息。
- 后处理阶段：在检索到最相关的句子节点后，系统会使用一个名为 MetadataReplacementPostProcessor 的后处理模块。该模块会读取到检索到的句子节点的元数据，并用元数据中存储的完整上下文窗口来替换节点中原来的单一句子内容。
- 生成阶段：最后，这些被替换了内容的、包含丰富上下文的节点被传递给LLM，用于生成最终的答案。

**为文本块附加结构化的元数据（Metadata）以避免对所有文本块进行搜索**: 先过滤，再搜索
- 元数据预过滤：首先通过元数据筛选，只在 document_type == '财报'、year == 2023 且 quarter == 'Q2' 的文档子集中进行搜索。
- 向量搜索：然后，在经过滤的、范围更小的文本块集合中，执行针对查询“关于AI的论述”的向量相似度搜索。