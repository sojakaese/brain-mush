# 4.1 混合检索
以Milvus，langchain，LlamaIndex，以及ColBERT，Reranker，Cross-Encoder，RankLLM，SentenceEmbeddingOptimizer, CRAG的检索实现为例，讨论检索优化的各种可能性。

## 4.1.1 用稀疏向量和密集向量嵌入的方式来进行混合检索

**复习一下稀疏向量和密集向量的概念**
- TF-IDF 和 BM25适用于稀疏向量 (Sparse Vectors) 权重计算，基于词频和逆文档频率来衡量文本之间的相似性，而和语义无关。优点无需训练，计算简单，缺点是无法捕捉词语的语义关系，容易受到同义词和多义词的影响。
举例下面是BM25的计算公式：
$$ Score(Q, D) = \sum_{i=1}^{n} IDF(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{avgdl})} $$

- Word2Vec、GloVe、以及所有基于 Transformer的模型生成的嵌入都适用于密集向量 (Dense Vectors)。优点：能够理语义关系和上下文，缺点：可解释性差（向量中的每个维度通常没有具体的物理意义），需要大量数据和计算资源进行训练，且在处理非常长的文本时可能效果不佳。

**举例比较这两种向量：**
先复习了COO格式表示稀疏向量。回顾了一下COO格式的稀疏矩阵存储方法。
稀疏向量在大多数维度上都是零，只有少数维度有非零值。密集向量在所有维度都有值，权重是训练的结果，无法直接解释。

## 4.1.2 混合检索
介绍了倒数排序融合 (Reciprocal Rank Fusion, RRF)和加权线性组合linear combination两种方法
- RRF 不关心不同检索系统的原始得分，只关心每个文档在各自结果集中的排名。
- 加权线性组合先将不同检索系统的得分归一化，然后通过权重参数 α 来进行线性组合。

练习：单独的稀疏向量检索，单独的密集向量检索都使用了filter，混合却没有。


# 4.2 查询建构
出发点：用LLM的能力来构建查询 Query 本身。实例为使用SelfQueryRetriever来查询，主要使用Query中的metadata条件来滤出搜寻结果。

思考：检索使用的document本身是固定的文本，检索的结果是查询首先和这个文本的比较，然后再和metadata的条件进行过滤。所以第二个查询，实际上是问题和documents比较的结果。

# 4.3 Text2SQL
以Text2SQL为例，讨论了检索优化的思路。

带有启发性的是: 
1. 在向量数据库进行三种查询：Query本身的语义查询，相关DDL即数据库的schema的信息查询，相关标注例子的查询，这三个查询答案，来总结出最终SQL查询语句的思路。
2. SQL查询和SQL查询的纠错都是下游任务，我们关注的是RAG优化，查询结果其实是3个部分。LLM生成是集成。

# 4.4 查询重构与查询分发
本节的意图为探讨如何优化查询输入，并且通过机制把查询通过逻辑和分类，分发到不同的检索器中去。

查询重构有如下方法：
- 提示工程 通过LLM的能力来重构查询
- 多查询分解 (Multi-query) 用解构问题的方法通过多个查询来获取答案。langchain的MultiQueryRetriever组件。
- 退步提示（Step-Back Prompting）使用抽象化问题，在上一层领域进行推理，然后重新进入场景进行回答。理论来自Google DeepMind。
- 假设性文档嵌入 (HyDE) 使用LLM生成假设性答案，然后将这些答案嵌入向量数据库中进行检索。思路：从“查询到文档”的匹配问题，转化为了“文档到文档”的匹配问题，从而提升检索的准确率。

查询分发有如下方法：
- 数据源路由 根据查询意图，将其路由到不同的知识库
- 组件路由 根据问题的复杂性，将其分配给不同的处理组件，以平衡成本和效果
- 提示模板路由 为不同类型的任务动态选择最优的提示词模板，以优化生成效果。

查询分发的实现有如下方法：
- 基于LLM的意图识别
- 基于其他部件比如LM的分类器

以上的路由分发方式，langchain和LlamaIndex都有实现。

# 4.5 检索进阶
本节介绍了优化检索加工的几种思路：
- 结果重排序 (Re-ranking) 使用更强大的模型对初步检索结果进行重新排序，以提升相关性。
- 结果压缩 (Result Compression) 通过摘要 提取关键内容或者丢弃无关内容来减少检索结果的冗余信息，从而优化检索结果。
- 结果校正 (Correcting) 通过纠错模型对检索结果进行修正，以提升准确性。
- 结果融合 (Fusion) 通过结合多个检索系统的结果来提升整体的检索效果。例子为自己实现的ColBERTReranker结合DocumentCompressor，在langchain中优化检索结果。

**重排序 (Re-ranking)**的不同实现的比较：
| 特性 | RRF | RankLLM | Cross-Encoder | ColBERT |
| :--- | :--- | :--- | :--- | :--- |
| **核心机制** | 融合多个排名 | LLM 推理，生成排序列表 | 联合编码查询与文档，计算单一相关分 | 独立编码，后期交互 |
| **计算成本** | 低（简单数学计算） | 中 (API 费用与延迟) | 高（N次模型推理） | 中（向量点积计算） |
| **交互粒度** | 无（仅排名） | 概念/语义级 | 句子级（Query-Doc Pair） | Token 级 |
| **适用场景** | 多路召回结果融合 | 高价值语义理解场景 | Top-K 精排 | Top-K 重排 |

**结果压缩** 介绍了langchain的 DocumentCompressor组件，支持多种压缩方法。llamaIndex的类似实现为SentenceEmbeddingOptimizer。

**结果校正** 介绍了CRAG 检索-评估-行动的工作流程，结合检索和生成模型来提升回答的准确性。
